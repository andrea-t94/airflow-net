1. Decided to generate 3 instructions per request. This proved to be really cost effective using batch messages, I spent <2$ (with one rewuest for one instruction at time >5)
2. created a lightweight DAG parser that checks basic things (e.g. missing import checks, Xcom, task groups, connection and task are properly working, Operators and Sesnor are properly inputed)
3. looking for quantised versions that can work decently on my mac m1 pro. I noticed that batch has to be extremely low, limited also the output tolkens and now looking for a cross platform inference solution that works with cpu -> llama.cpp with gguf models