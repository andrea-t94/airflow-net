{"instruction": "Create a dynamic task routing DAG that randomly selects one of four predefined branches during each daily run. Design a workflow that demonstrates flexible task execution with random path selection.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import timedelta, datetime\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom random import choice\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndef random_task():\n    return choice(['task1', 'task2', 'task3', 'task4'])\n\ndef execute_task(task):\n    print(f\"Executing task: {task}\")\n\nwith DAG(\n    dag_id='dynamic_task_routing_dag',\n    default_args=default_args,\n    schedule_interval='@daily',\n    catchup=False,\n    max_active_runs=1,\n) as dag:\n    task1 = PythonOperator(\n        task_id='task1',\n        python_callable=random_task,\n        provide_context=True,\n    )\n    task2 = PythonOperator(\n        task_id='task2',\n        python_callable=random_task,\n        provide_context=True,\n    )\n    task3 = PythonOperator(\n        task_id='task3',\n        python_callable=random_task,\n        provide_context=True,\n    )\n    task4 = PythonOperator(\n        task_id='task4',\n        python_callable=random_task,\n        provide_context=True,\n    )\n\n    task1 >> execute_task >> task2\n    task2 >> execute_task >> task3\n    task3 >> execute_task >> task4", "metadata": {"file_name": "dag_0_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 1, "backend": "llama.cpp"}}
{"instruction": "Build an Airflow pipeline that showcases conditional task execution using the BranchPythonOperator, illustrating how tasks can dynamically choose their execution path based on runtime logic. Implement a workflow that randomly selects and executes one of multiple parallel task branches.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import BranchPythonOperator, PythonOperator\nfrom airflow.operators.bash import BashOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'random_task_branching',\n    default_args=default_args,\n    schedule_interval=timedelta(days=1),\n)\n\ndef branch_task():\n    return 'task1'\n\ndef task1():\n    print(\"Executing task1\")\n\ndef task2():\n    print(\"Executing task2\")\n\ndef task3():\n    print(\"Executing task3\")\n\ndef task4():\n    print(\"Executing task4\")\n\ndef task5():\n    print(\"Executing task5\")\n\ndef task6():\n    print(\"Executing task6\")\n\ndef task7():\n    print(\"Executing task7\")\n\ndef task8():\n    print(\"Executing task8\")\n\ndef task9():\n    print(\"Executing task9\")\n\ndef task10():\n    print(\"Executing task10\")\n\ndef task11():\n    print(\"Executing task11\")\n\ndef task12():\n    print(\"Executing task12\")\n\ndef task13():\n    print(\"Executing task13\")\n\ndef task14():\n    print(\"Executing task14\")\n\ndef task15():\n    print(\"Executing task15\")\n\ndef task16():\n    print(\"Executing task16\")\n\ndef task17():\n    print(\"Executing task17\")\n\ndef task18():\n    print(\"Executing task18\")\n\ndef task19():\n    print(\"Executing task19\")\n\ndef task20():\n    print(\"Executing task20\")\n\ndef task21():\n    print(\"Executing task21\")\n\ndef task22():\n    print(\"Executing task22\")\n\ndef task23():\n    print(\"Executing task23\")\n\ndef task24():\n    print(\"Executing task24\")\n\ndef task25():\n    print(\"Executing task25\")\n\ndef task26():\n    print(\"Executing task26\")\n\ndef task27():\n    print(\"Executing task27\")\n\ndef task28():\n    print(\"Executing task28\")\n\ndef task29():\n    print(\"Executing task29\")\n\ndef task30():\n    print(\"Executing task30\")\n\ndef task31():\n    print(\"Executing task31\")\n\ndef task32():\n    print(\"Executing task32\")\n\ndef task33():\n    print(\"Executing task33\")\n\ndef task34():\n    print(\"Executing task34\")\n\ndef task35():\n    print(\"Executing task35\")\n\ndef task36():\n    print(\"Executing task36\")\n\ndef task37():\n    print(\"Executing task37\")\n\ndef task38():\n    print(\"Executing task38\")\n\ndef task39():\n    print(\"Executing task39\")\n\ndef task40():\n    print(\"Executing task40\")\n\ndef task41():\n    print(\"Executing task41\")\n\ndef task42():\n    print(\"Executing task42\")\n\ndef task43():\n    print(\"Executing task43\")\n\ndef task44():\n    print(\"Executing task44\")\n\ndef task45():\n    print(\"Executing task45\")\n\ndef task46():\n    print(\"Executing task46\")\n\ndef task47():\n    print(\"Executing task47\")\n\ndef task48():\n    print(\"Executing task48\")\n\ndef task49():\n    print(\"Executing task49\")\n\ndef task50():\n    print(\"Executing task50\")\n\ndef task51():\n    print(\"Executing task51\")\n\ndef task52():\n    print(\"Executing task52\")\n\ndef task53():\n    print(\"Executing task53\")\n\ndef task54():\n    print(\"Executing task54\")\n\ndef task55():\n    print(\"Executing task55\")\n\ndef task56():\n    print(\"Executing task56\")\n\ndef task57():\n    print(\"Executing task57\")\n\ndef task58():\n    print(\"Executing task58\")\n\ndef task59():\n    print(\"Executing task59\")\n\ndef task60():\n    print(\"Executing task60\")\n\ndef task61():\n    print(\"Executing task61\")\n\ndef task62():\n    print(\"Executing task62\")\n\ndef task63():\n    print(\"Executing task63\")\n\ndef task64():\n    print(\"Executing task64\")\n\ndef task65():\n    print(\"Executing task65\")\n\ndef task66():\n    print(\"Executing task66\")\n\ndef task67():\n    print(\"Executing task67\")\n\ndef task68():\n    print(\"Executing task68\")\n\ndef task69():\n    print(\"Executing task69\")\n\ndef task70():\n    print(\"Executing task70\")\n\ndef task71():\n    print(\"Executing task", "metadata": {"file_name": "dag_0_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 2, "backend": "llama.cpp"}}
{"instruction": "Develop an Airflow DAG that simulates a decision-making process where a single initial task triggers a random selection of processing paths. Create a workflow that demonstrates how data processing can be dynamically routed through different branches based on runtime conditions.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.dummy import DummyOperator\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.email import EmailOperator\nfrom airflow.operators.postgres_operator import PostgresOperator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftOperator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3Operator\nfrom airflow.operators.postgres_operator import PostgresToRedshiftToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3ToS3To", "metadata": {"file_name": "dag_0_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 3, "backend": "llama.cpp"}}
{"instruction": "Design a demonstration DAG that showcases multiple Bash command executions with different task dependencies. Create a workflow that runs several echo commands and demonstrates task chaining and conditional execution.", "input": {"airflow_version": "2.7.2"}, "output": "from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.operators.bash_operator import BashOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'bash_command_execution',\n    default_args=default_args,\n    schedule_interval=timedelta(days=1),\n)\n\ndef echo_command():\n    bash_operator = BashOperator(\n        task_id='echo_command',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 = BashOperator(\n        task_id='echo_command_2',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_3 = BashOperator(\n        task_id='echo_command_3',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 >> echo_command_3\n\ndef echo_command_with_condition():\n    bash_operator = BashOperator(\n        task_id='echo_command_with_condition',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 = BashOperator(\n        task_id='echo_command_2',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_3 = BashOperator(\n        task_id='echo_command_3',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 >> echo_command_3\n\ndef echo_command_with_task_chain():\n    bash_operator = BashOperator(\n        task_id='echo_command_with_task_chain',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 = BashOperator(\n        task_id='echo_command_2',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_3 = BashOperator(\n        task_id='echo_command_3',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 >> echo_command_3\n\ndef echo_command_with_task_chain_with_condition():\n    bash_operator = BashOperator(\n        task_id='echo_command_with_task_chain_with_condition',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 = BashOperator(\n        task_id='echo_command_2',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_3 = BashOperator(\n        task_id='echo_command_3',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    echo_command_2 >> echo_command_3\n\necho_command >> echo_command_with_condition\necho_command_with_condition >> echo_command_with_task_chain\necho_command_with_task_chain >> echo_command_with_task_chain_with_condition\necho_command_with_task_chain_with_condition >> echo_command_with_task_chain_with_condition", "metadata": {"file_name": "dag_1_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 4, "backend": "llama.cpp"}}
{"instruction": "Build an Airflow pipeline that illustrates task orchestration techniques using BashOperator, including parallel task generation, sequential dependencies, and handling potential task skipping scenarios. Develop a DAG that explores different ways of defining and connecting computational tasks.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.python import PythonOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'parallel_tasks',\n    default_args=default_args,\n    schedule_interval='@daily',\n)\n\ndef parallel_task():\n    bash_task = BashOperator(\n        task_id='parallel_task',\n        bash_command='echo \"Parallel task executed successfully!\"',\n        dag=dag,\n    )\n\n    bash_task2 = BashOperator(\n        task_id='parallel_task2',\n        bash_command='echo \"Parallel task executed successfully!\"',\n        dag=dag,\n    )\n\n    bash_task2.set_upstream(bash_task)\n\nparallel_task2 = PythonOperator(\n    task_id='parallel_task2',\n    python_callable=parallel_task,\n    dag=dag,\n)\n\nparallel_task2.set_upstream(bash_task)", "metadata": {"file_name": "dag_1_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 5, "backend": "llama.cpp"}}
{"instruction": "Construct an example workflow that simulates a basic data processing pipeline using shell commands, showing how Airflow can coordinate multiple computational steps with different execution patterns. Create a DAG that demonstrates dynamic task generation and conditional execution strategies.", "input": {"airflow_version": "2.7.2"}, "output": "from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'basic_data_processing_pipeline',\n    default_args=default_args,\n    schedule_interval=timedelta(days=1),\n)\n\ndef generate_tasks():\n    bash_task = BashOperator(\n        task_id='bash_task',\n        bash_command='echo \"Hello, World!\"',\n        dag=dag,\n    )\n\n    python_task = PythonOperator(\n        task_id='python_task',\n        python_callable=print,\n        op_args=['Hello, World!'],\n        dag=dag,\n    )\n\n    return bash_task, python_task\n\nbash_task, python_task = generate_tasks()\n\nbash_task >> python_task", "metadata": {"file_name": "dag_1_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 6, "backend": "llama.cpp"}}
{"instruction": "Design a dynamic workflow that randomly selects and executes one of four predefined branches during each daily run. Create a DAG that demonstrates flexible task routing using Python's random selection and Airflow's branching capabilities.", "input": {"airflow_version": "2.7.2"}, "output": "from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.operators.python import PythonOperator\nfrom random import choice\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'dynamic_workflow',\n    default_args=default_args,\n    schedule_interval=timedelta(days=1),\n)\n\ndef select_branch():\n    branches = ['branch1', 'branch2', 'branch3', 'branch4']\n    return choice(branches)\n\ndef execute_branch(branch):\n    print(f\"Executing branch: {branch}\")\n\nwith dag:\n    task1 = PythonOperator(\n        task_id='task1',\n        python_callable=select_branch,\n        dag=dag,\n    )\n\n    task2 = PythonOperator(\n        task_id='task2',\n        python_callable=execute_branch,\n        op_kwargs={'branch': 'branch1'},\n        dag=dag,\n    )\n\n    task3 = PythonOperator(\n        task_id='task3',\n        python_callable=execute_branch,\n        op_kwargs={'branch': 'branch2'},\n        dag=dag,\n    )\n\n    task4 = PythonOperator(\n        task_id='task4',\n        python_callable=execute_branch,\n        op_kwargs={'branch': 'branch3'},\n        dag=dag,\n    )\n\n    task5 = PythonOperator(\n        task_id='task5',\n        python_callable=execute_branch,\n        op_kwargs={'branch': 'branch4'},\n        dag=dag,\n    )", "metadata": {"file_name": "dag_2_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 7, "backend": "llama.cpp"}}
{"instruction": "Build an Airflow pipeline that showcases conditional task execution using a branching mechanism that randomly chooses between multiple potential workflow paths. Implement a DAG that illustrates how to dynamically select and execute different task sequences based on runtime decisions.", "input": {"airflow_version": "2.7.2"}, "output": "from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.operators.python import PythonOperator\nfrom random import choice\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndef random_task():\n    print(\"Random task executed.\")\n\ndef select_task(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef task1():\n    print(\"Task 1 executed.\")\n\ndef task2():\n    print(\"Task 2 executed.\")\n\ndef task3():\n    print(\"Task 3 executed.\")\n\ndef select_task_sequence(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task2(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task3(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task4(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task5(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task6(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task7(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task8(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task9(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task10(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task11(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task12(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task13(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task14(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task == \"task3\":\n        return task3\n    else:\n        return None\n\ndef select_task_sequence_task15(task):\n    if task == \"task1\":\n        return task1\n    elif task == \"task2\":\n        return task2\n    elif task ==", "metadata": {"file_name": "dag_2_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 8, "backend": "llama.cpp"}}
{"instruction": "Develop an Airflow DAG that simulates a decision-making process where a single task randomly determines which subsequent tasks will be executed. Create a workflow that demonstrates how to implement probabilistic routing in data processing pipelines using Airflow's task branching decorator.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom random import choice\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndef random_task():\n    return choice(['task1', 'task2', 'task3'])\n\ndef execute_next_task(task_id):\n    return BashOperator(\n        task_id=task_id,\n        bash_command='echo \"Executing next task: {}\"'.format(task_id),\n    )\n\ndef process_data():\n    return BashOperator(\n        task_id='process_data',\n        bash_command='echo \"Processing data\"',\n    )\n\ndef main():\n    dag = DAG(\n        'random_task_dag',\n        default_args=default_args,\n        schedule_interval='@daily',\n    )\n\n    task1 = PythonOperator(\n        task_id='task1',\n        python_callable=random_task,\n    )\n\n    task2 = PythonOperator(\n        task_id='task2',\n        python_callable=random_task,\n    )\n\n    task3 = PythonOperator(\n        task_id='task3',\n        python_callable=random_task,\n    )\n\n    task4 = PythonOperator(\n        task_id='task4',\n        python_callable=random_task,\n    )\n\n    task5 = PythonOperator(\n        task_id='task5',\n        python_callable=random_task,\n    )\n\n    task6 = PythonOperator(\n        task_id='task6',\n        python_callable=random_task,\n    )\n\n    task7 = PythonOperator(\n        task_id='task7',\n        python_callable=random_task,\n    )\n\n    task8 = PythonOperator(\n        task_id='task8',\n        python_callable=random_task,\n    )\n\n    task9 = PythonOperator(\n        task_id='task9',\n        python_callable=random_task,\n    )\n\n    task10 = PythonOperator(\n        task_id='task10',\n        python_callable=random_task,\n    )\n\n    task11 = PythonOperator(\n        task_id='task11',\n        python_callable=random_task,\n    )\n\n    task12 = PythonOperator(\n        task_id='task12',\n        python_callable=random_task,\n    )\n\n    task13 = PythonOperator(\n        task_id='task13',\n        python_callable=random_task,\n    )\n\n    task14 = PythonOperator(\n        task_id='task14',\n        python_callable=random_task,\n    )\n\n    task15 = PythonOperator(\n        task_id='task15',\n        python_callable=random_task,\n    )\n\n    task16 = PythonOperator(\n        task_id='task16',\n        python_callable=random_task,\n    )\n\n    task17 = PythonOperator(\n        task_id='task17',\n        python_callable=random_task,\n    )\n\n    task18 = PythonOperator(\n        task_id='task18',\n        python_callable=random_task,\n    )\n\n    task19 = PythonOperator(\n        task_id='task19',\n        python_callable=random_task,\n    )\n\n    task20 = PythonOperator(\n        task_id='task20',\n        python_callable=random_task,\n    )\n\n    task21 = PythonOperator(\n        task_id='task21',\n        python_callable=random_task,\n    )\n\n    task22 = PythonOperator(\n        task_id='task22',\n        python_callable=random_task,\n    )\n\n    task23 = PythonOperator(\n        task_id='task23',\n        python_callable=random_task,\n    )\n\n    task24 = PythonOperator(\n        task_id='task24',\n        python_callable=random_task,\n    )\n\n    task25 = PythonOperator(\n        task_id='task25',\n        python_callable=random_task,\n    )\n\n    task26 = PythonOperator(\n        task_id='task26',\n        python_callable=random_task,\n    )\n\n    task27 = PythonOperator(\n        task_id='task27',\n        python_callable=random_task,\n    )\n\n    task28 = PythonOperator(\n        task_id='task28',\n        python_callable=random_task,\n    )\n\n    task29 = PythonOperator(\n        task_id='task29',\n        python_callable=random_task,\n    )\n\n    task30 = PythonOperator(\n        task_id='task30',\n        python_callable=random_task,\n    )\n\n    task31 = PythonOperator(\n        task_id='task31',\n        python_callable=random_task,\n    )\n\n    task32 = PythonOperator(\n        task_id='task32',\n        python_callable=random_task,\n    )\n\n    task33 = PythonOperator(\n        task_id='task33',\n        python_callable=random_task,\n    )\n\n    task34 = PythonOperator(\n        task_id='task34',\n        python_callable=random_task,\n    )\n\n    task35 = PythonOperator(\n        task_id='task35',\n        python_callable=random_task,\n    )\n\n    task", "metadata": {"file_name": "dag_2_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 9, "backend": "llama.cpp"}}
{"instruction": "Design a workflow that demonstrates conditional task execution based on the day of the week. Create a DAG that branches tasks differently for weekdays and weekends, showing how Airflow can dynamically route workflow paths.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'conditional_task_execution',\n    default_args=default_args,\n    schedule_interval='@daily',\n)\n\ndef weekday_task():\n    print(f\"Executing task on {datetime.now().strftime('%A')}\")\n\ndef weekend_task():\n    print(f\"Executing task on {datetime.now().strftime('%A')}\")\n\nwith dag:\n    task1 = PythonOperator(\n        task_id='weekday_task',\n        python_callable=weekday_task,\n        dag=dag,\n    )\n\n    task2 = BashOperator(\n        task_id='weekend_task',\n        bash_command='echo \"Executing task on Weekend\"',\n        dag=dag,\n    )\n\n    task1 >> task2", "metadata": {"file_name": "dag_3_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 10, "backend": "llama.cpp"}}
{"instruction": "Build an Airflow pipeline that showcases branching logic using BranchDayOfWeekOperator to demonstrate conditional task selection. Implement a workflow that executes different tasks based on whether the current day matches specific day criteria.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.dummy import DummyOperator\n\ndef branch_day_of_week():\n    # Branch based on the current day of the week\n    if datetime.now().weekday() == 0:\n        return \"Monday\"\n    elif datetime.now().weekday() == 1:\n        return \"Tuesday\"\n    elif datetime.now().weekday() == 2:\n        return \"Wednesday\"\n    elif datetime.now().weekday() == 3:\n        return \"Thursday\"\n    elif datetime.now().weekday() == 4:\n        return \"Friday\"\n    elif datetime.now().weekday() == 5:\n        return \"Saturday\"\n    elif datetime.now().weekday() == 6:\n        return \"Sunday\"\n\ndef execute_task(task):\n    print(f\"Executing task: {task}\")\n\ndef execute_task2(task):\n    print(f\"Executing task: {task}\")\n\nwith DAG(\n    dag_id=\"branch_day_of_week_dag\",\n    start_date=datetime(2023, 1, 1),\n    schedule_interval=\"@daily\",\n    catchup=False,\n    tags=[\"example\"],\n) as dag:\n    start = DummyOperator(task_id=\"start\")\n\n    task1 = BashOperator(\n        task_id=\"task1\",\n        bash_command=\"echo 'Task 1 executed'\",\n        dag=dag,\n    )\n\n    task2 = BashOperator(\n        task_id=\"task2\",\n        bash_command=\"echo 'Task 2 executed'\",\n        dag=dag,\n    )\n\n    task3 = BashOperator(\n        task_id=\"task3\",\n        bash_command=\"echo 'Task 3 executed'\",\n        dag=dag,\n    )\n\n    task4 = BashOperator(\n        task_id=\"task4\",\n        bash_command=\"echo 'Task 4 executed'\",\n        dag=dag,\n    )\n\n    task5 = BashOperator(\n        task_id=\"task5\",\n        bash_command=\"echo 'Task 5 executed'\",\n        dag=dag,\n    )\n\n    task6 = BashOperator(\n        task_id=\"task6\",\n        bash_command=\"echo 'Task 6 executed'\",\n        dag=dag,\n    )\n\n    task7 = BashOperator(\n        task_id=\"task7\",\n        bash_command=\"echo 'Task 7 executed'\",\n        dag=dag,\n    )\n\n    task8 = BashOperator(\n        task_id=\"task8\",\n        bash_command=\"echo 'Task 8 executed'\",\n        dag=dag,\n    )\n\n    task9 = BashOperator(\n        task_id=\"task9\",\n        bash_command=\"echo 'Task 9 executed'\",\n        dag=dag,\n    )\n\n    task10 = BashOperator(\n        task_id=\"task10\",\n        bash_command=\"echo 'Task 10 executed'\",\n        dag=dag,\n    )\n\n    task11 = BashOperator(\n        task_id=\"task11\",\n        bash_command=\"echo 'Task 11 executed'\",\n        dag=dag,\n    )\n\n    task12 = BashOperator(\n        task_id=\"task12\",\n        bash_command=\"echo 'Task 12 executed'\",\n        dag=dag,\n    )\n\n    task13 = BashOperator(\n        task_id=\"task13\",\n        bash_command=\"echo 'Task 13 executed'\",\n        dag=dag,\n    )\n\n    task14 = BashOperator(\n        task_id=\"task14\",\n        bash_command=\"echo 'Task 14 executed'\",\n        dag=dag,\n    )\n\n    task15 = BashOperator(\n        task_id=\"task15\",\n        bash_command=\"echo 'Task 15 executed'\",\n        dag=dag,\n    )\n\n    task16 = BashOperator(\n        task_id=\"task16\",\n        bash_command=\"echo 'Task 16 executed'\",\n        dag=dag,\n    )\n\n    task17 = BashOperator(\n        task_id=\"task17\",\n        bash_command=\"echo 'Task 17 executed'\",\n        dag=dag,\n    )\n\n    task18 = BashOperator(\n        task_id=\"task18\",\n        bash_command=\"echo 'Task 18 executed'\",\n        dag=dag,\n    )\n\n    task19 = BashOperator(\n        task_id=\"task19\",\n        bash_command=\"echo 'Task 19 executed'\",\n        dag=dag,\n    )\n\n    task20 = BashOperator(\n        task_id=\"task20\",\n        bash_command=\"echo 'Task 20 executed'\",\n        dag=dag,\n    )\n\n    task21 = BashOperator(\n        task_id=\"task21\",\n        bash_command=\"echo 'Task 21 executed'\",\n        dag=dag,\n    )\n\n    task22 = BashOperator(\n        task_id=\"task22\",\n        bash_command=\"echo 'Task 22 executed'\",\n        dag=dag,\n    )\n\n    task23 = BashOperator(\n        task_id=\"task23\",\n        bash_command", "metadata": {"file_name": "dag_3_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 11, "backend": "llama.cpp"}}
{"instruction": "Develop an Airflow DAG that illustrates dynamic task routing using day-of-week conditions for data processing workflows. Create a scenario where tasks are selectively executed based on whether the current day meets predefined scheduling requirements.", "input": {"airflow_version": "2.7.2"}, "output": "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.operators.dummy_operator import DummyOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'dynamic_day_of_week_task_routing',\n    default_args=default_args,\n    schedule_interval='@daily',\n)\n\nstart_task = DummyOperator(task_id='start_task', dag=dag)\n\ndef process_data():\n    print(\"Processing data\")\n\ndef process_data_with_day_of_week():\n    print(\"Processing data with day of week\")\n\ntask1 = PythonOperator(\n    task_id='task1',\n    python_callable=process_data,\n    dag=dag,\n)\n\ntask2 = PythonOperator(\n    task_id='task2',\n    python_callable=process_data_with_day_of_week,\n    dag=dag,\n)\n\ntask1 >> task2\nstart_task >> [task1, task2]", "metadata": {"file_name": "dag_3_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 12, "backend": "llama.cpp"}}
{"instruction": "Design a data quality monitoring workflow that tracks data integrity during an ingestion process. Create a DAG that handles both successful data processing and error scenarios with clear branching and reporting.", "input": {"airflow_version": "2.7.2"}, "output": "from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.dummy import DummyOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'data_quality_monitoring',\n    default_args=default_args,\n    schedule_interval='@daily',\n)\n\nstart = DummyOperator(task_id='start', dag=dag)\n\ningest_data = BashOperator(\n    task_id='ingest_data',\n    bash_command='python /path/to/ingest_data.py',\n    dag=dag,\n)\n\ncheck_data_quality = PythonOperator(\n    task_id='check_data_quality',\n    python_callable=check_data_quality,\n    op_args=[ingest_data],\n    dag=dag,\n)\n\nend = DummyOperator(task_id='end', dag=dag)\n\nstart >> ingest_data >> check_data_quality >> end", "metadata": {"file_name": "dag_4_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 13, "backend": "llama.cpp"}}
{"instruction": "Build an Airflow pipeline that demonstrates conditional task execution based on data integrity checks. Implement a workflow that can automatically route tasks differently depending on whether data passes or fails validation.", "input": {"airflow_version": "2.7.2"}, "output": "from airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\nfrom airflow.operators.bash_operator import BashOperator\nfrom airflow.operators.dummy_operator import DummyOperator\n\ndef validate_data(context):\n    # Perform data validation logic here\n    print(\"Data validation successful\")\n\ndef fail_data(context):\n    # Perform data validation logic here\n    print(\"Data validation failed\")\n\ndef route_data(context):\n    # Route data based on validation result\n    print(\"Data passed validation, routing to next task\")\n\ndef fail_data_check(context):\n    # Perform data validation logic here\n    print(\"Data validation failed, routing to fail task\")\n\ndef success_data_check(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_2(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_3(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_4(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_5(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_6(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_7(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_8(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_9(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_10(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_11(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_12(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_13(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_14(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_15(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_16(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_17(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_18(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_19(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_20(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_21(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_22(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_23(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_24(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_25(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_26(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_27(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_28(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_29(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_30(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_31(context):\n    # Perform data validation logic here\n    print(\"Data validation successful, routing to success task\")\n\ndef success_data_check_32", "metadata": {"file_name": "dag_4_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 14, "backend": "llama.cpp"}}
{"instruction": "Develop a data processing pipeline that includes stages for data ingestion, analysis, integrity verification, and error handling. Create a workflow that can gracefully manage data quality issues and generate appropriate reports or alerts.", "input": {"airflow_version": "2.7.2"}, "output": "from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.dummy import DummyOperator\n\ndefault_args = {\n    'owner': 'airflow',\n    'start_date': datetime(2023, 1, 1),\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndag = DAG(\n    'data_processing_pipeline',\n    default_args=default_args,\n    schedule_interval=timedelta(days=1),\n)\n\nstart = DummyOperator(task_id='start', dag=dag)\n\ningest_data = BashOperator(\n    task_id='ingest_data',\n    bash_command='python /path/to/ingest_data.py',\n    dag=dag,\n)\n\nprocess_data = PythonOperator(\n    task_id='process_data',\n    python_callable=process_data,\n    op_args=[ingest_data],\n    dag=dag,\n)\n\nverify_data = BashOperator(\n    task_id='verify_data',\n    bash_command='python /path/to/verify_data.py',\n    dag=dag,\n)\n\nhandle_errors = BashOperator(\n    task_id='handle_errors',\n    bash_command='python /path/to/handle_errors.py',\n    dag=dag,\n)\n\nend = DummyOperator(task_id='end', dag=dag)\n\nstart >> ingest_data >> process_data >> verify_data >> handle_errors >> end", "metadata": {"file_name": "dag_4_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "model": "qwen2-1.5b-instruct-q4_k_m-gguf", "generation_id": 15, "backend": "llama.cpp"}}
