{"instruction": "Create a dynamic task routing DAG that randomly selects one of four predefined branches during each daily run. Design a workflow that demonstrates flexible task execution with random path selection.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the BranchPythonOperator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.python import BranchPythonOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(\n        task_id=\"run_this_first\",\n    )\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    branching = BranchPythonOperator(\n        task_id=\"branching\",\n        python_callable=lambda: random.choice(options),\n    )\n    run_this_first >> branching\n\n    join = EmptyOperator(\n        task_id=\"join\",\n        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,\n    )\n\n    for option in options:\n        t = EmptyOperator(\n            task_id=option,\n        )\n\n        empty_follow = EmptyOperator(\n            task_id=\"follow_\" + option,\n        )\n\n        # Label is optional here, but it can help identify more complex branches\n        branching >> Label(option) >> t >> empty_follow >> join", "metadata": {"file_name": "dag_0_variant_1", "instruction_source": "claude-3.5", "variant_number": 1}}
{"instruction": "Build an Airflow pipeline that showcases conditional task execution using the BranchPythonOperator, illustrating how tasks can dynamically choose their execution path based on runtime logic. Implement a workflow that randomly selects and executes one of multiple parallel task branches.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the BranchPythonOperator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.python import BranchPythonOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(\n        task_id=\"run_this_first\",\n    )\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    branching = BranchPythonOperator(\n        task_id=\"branching\",\n        python_callable=lambda: random.choice(options),\n    )\n    run_this_first >> branching\n\n    join = EmptyOperator(\n        task_id=\"join\",\n        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,\n    )\n\n    for option in options:\n        t = EmptyOperator(\n            task_id=option,\n        )\n\n        empty_follow = EmptyOperator(\n            task_id=\"follow_\" + option,\n        )\n\n        # Label is optional here, but it can help identify more complex branches\n        branching >> Label(option) >> t >> empty_follow >> join", "metadata": {"file_name": "dag_0_variant_2", "instruction_source": "claude-3.5", "variant_number": 2}}
{"instruction": "Develop an Airflow DAG that simulates a decision-making process where a single initial task triggers a random selection of processing paths. Create a workflow that demonstrates how data processing can be dynamically routed through different branches based on runtime conditions.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the BranchPythonOperator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.python import BranchPythonOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(\n        task_id=\"run_this_first\",\n    )\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    branching = BranchPythonOperator(\n        task_id=\"branching\",\n        python_callable=lambda: random.choice(options),\n    )\n    run_this_first >> branching\n\n    join = EmptyOperator(\n        task_id=\"join\",\n        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,\n    )\n\n    for option in options:\n        t = EmptyOperator(\n            task_id=option,\n        )\n\n        empty_follow = EmptyOperator(\n            task_id=\"follow_\" + option,\n        )\n\n        # Label is optional here, but it can help identify more complex branches\n        branching >> Label(option) >> t >> empty_follow >> join", "metadata": {"file_name": "dag_0_variant_3", "instruction_source": "claude-3.5", "variant_number": 3}}
{"instruction": "Design a demonstration DAG that showcases multiple Bash command executions with different task dependencies. Create a workflow that runs several echo commands and demonstrates task chaining and conditional execution.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the BashOperator.\"\"\"\nfrom __future__ import annotations\n\nimport datetime\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.empty import EmptyOperator\n\nwith DAG(\n    dag_id=\"example_bash_operator\",\n    schedule=\"0 0 * * *\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    dagrun_timeout=datetime.timedelta(minutes=60),\n    tags=[\"example\", \"example2\"],\n    params={\"example_key\": \"example_value\"},\n) as dag:\n    run_this_last = EmptyOperator(\n        task_id=\"run_this_last\",\n    )\n\n    # [START howto_operator_bash]\n    run_this = BashOperator(\n        task_id=\"run_after_loop\",\n        bash_command=\"echo 1\",\n    )\n    # [END howto_operator_bash]\n\n    run_this >> run_this_last\n\n    for i in range(3):\n        task = BashOperator(\n            task_id=f\"runme_{i}\",\n            bash_command='echo \"{{ task_instance_key_str }}\" && sleep 1',\n        )\n        task >> run_this\n\n    # [START howto_operator_bash_template]\n    also_run_this = BashOperator(\n        task_id=\"also_run_this\",\n        bash_command='echo \"ti_key={{ task_instance_key_str }}\"',\n    )\n    # [END howto_operator_bash_template]\n    also_run_this >> run_this_last\n\n# [START howto_operator_bash_skip]\nthis_will_skip = BashOperator(\n    task_id=\"this_will_skip\",\n    bash_command='echo \"hello world\"; exit 99;',\n    dag=dag,\n)\n# [END howto_operator_bash_skip]\nthis_will_skip >> run_this_last\n\nif __name__ == \"__main__\":\n    dag.test()", "metadata": {"file_name": "dag_1_variant_1", "instruction_source": "claude-3.5", "variant_number": 1}}
{"instruction": "Build an Airflow pipeline that illustrates task orchestration techniques using BashOperator, including parallel task generation, sequential dependencies, and handling potential task skipping scenarios. Develop a DAG that explores different ways of defining and connecting computational tasks.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the BashOperator.\"\"\"\nfrom __future__ import annotations\n\nimport datetime\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.empty import EmptyOperator\n\nwith DAG(\n    dag_id=\"example_bash_operator\",\n    schedule=\"0 0 * * *\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    dagrun_timeout=datetime.timedelta(minutes=60),\n    tags=[\"example\", \"example2\"],\n    params={\"example_key\": \"example_value\"},\n) as dag:\n    run_this_last = EmptyOperator(\n        task_id=\"run_this_last\",\n    )\n\n    # [START howto_operator_bash]\n    run_this = BashOperator(\n        task_id=\"run_after_loop\",\n        bash_command=\"echo 1\",\n    )\n    # [END howto_operator_bash]\n\n    run_this >> run_this_last\n\n    for i in range(3):\n        task = BashOperator(\n            task_id=f\"runme_{i}\",\n            bash_command='echo \"{{ task_instance_key_str }}\" && sleep 1',\n        )\n        task >> run_this\n\n    # [START howto_operator_bash_template]\n    also_run_this = BashOperator(\n        task_id=\"also_run_this\",\n        bash_command='echo \"ti_key={{ task_instance_key_str }}\"',\n    )\n    # [END howto_operator_bash_template]\n    also_run_this >> run_this_last\n\n# [START howto_operator_bash_skip]\nthis_will_skip = BashOperator(\n    task_id=\"this_will_skip\",\n    bash_command='echo \"hello world\"; exit 99;',\n    dag=dag,\n)\n# [END howto_operator_bash_skip]\nthis_will_skip >> run_this_last\n\nif __name__ == \"__main__\":\n    dag.test()", "metadata": {"file_name": "dag_1_variant_2", "instruction_source": "claude-3.5", "variant_number": 2}}
{"instruction": "Construct an example workflow that simulates a basic data processing pipeline using shell commands, showing how Airflow can coordinate multiple computational steps with different execution patterns. Create a DAG that demonstrates dynamic task generation and conditional execution strategies.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the BashOperator.\"\"\"\nfrom __future__ import annotations\n\nimport datetime\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.empty import EmptyOperator\n\nwith DAG(\n    dag_id=\"example_bash_operator\",\n    schedule=\"0 0 * * *\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    dagrun_timeout=datetime.timedelta(minutes=60),\n    tags=[\"example\", \"example2\"],\n    params={\"example_key\": \"example_value\"},\n) as dag:\n    run_this_last = EmptyOperator(\n        task_id=\"run_this_last\",\n    )\n\n    # [START howto_operator_bash]\n    run_this = BashOperator(\n        task_id=\"run_after_loop\",\n        bash_command=\"echo 1\",\n    )\n    # [END howto_operator_bash]\n\n    run_this >> run_this_last\n\n    for i in range(3):\n        task = BashOperator(\n            task_id=f\"runme_{i}\",\n            bash_command='echo \"{{ task_instance_key_str }}\" && sleep 1',\n        )\n        task >> run_this\n\n    # [START howto_operator_bash_template]\n    also_run_this = BashOperator(\n        task_id=\"also_run_this\",\n        bash_command='echo \"ti_key={{ task_instance_key_str }}\"',\n    )\n    # [END howto_operator_bash_template]\n    also_run_this >> run_this_last\n\n# [START howto_operator_bash_skip]\nthis_will_skip = BashOperator(\n    task_id=\"this_will_skip\",\n    bash_command='echo \"hello world\"; exit 99;',\n    dag=dag,\n)\n# [END howto_operator_bash_skip]\nthis_will_skip >> run_this_last\n\nif __name__ == \"__main__\":\n    dag.test()", "metadata": {"file_name": "dag_1_variant_3", "instruction_source": "claude-3.5", "variant_number": 3}}
{"instruction": "Design a dynamic workflow that randomly selects and executes one of four predefined branches during each daily run. Create a DAG that demonstrates flexible task routing using Python's random selection and Airflow's branching capabilities.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the ``@task.branch`` TaskFlow API decorator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_python_operator_decorator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(task_id=\"run_this_first\")\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    @task.branch(task_id=\"branching\")\n    def random_choice(choices: list[str]) -> str:\n        return random.choice(choices)\n\n    random_choice_instance = random_choice(choices=options)\n\n    run_this_first >> random_choice_instance\n\n    join = EmptyOperator(task_id=\"join\", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)\n\n    for option in options:\n        t = EmptyOperator(task_id=option)\n\n        empty_follow = EmptyOperator(task_id=\"follow_\" + option)\n\n        # Label is optional here, but it can help identify more complex branches\n        random_choice_instance >> Label(option) >> t >> empty_follow >> join", "metadata": {"file_name": "dag_2_variant_1", "instruction_source": "claude-3.5", "variant_number": 1}}
{"instruction": "Build an Airflow pipeline that showcases conditional task execution using a branching mechanism that randomly chooses between multiple potential workflow paths. Implement a DAG that illustrates how to dynamically select and execute different task sequences based on runtime decisions.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the ``@task.branch`` TaskFlow API decorator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_python_operator_decorator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(task_id=\"run_this_first\")\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    @task.branch(task_id=\"branching\")\n    def random_choice(choices: list[str]) -> str:\n        return random.choice(choices)\n\n    random_choice_instance = random_choice(choices=options)\n\n    run_this_first >> random_choice_instance\n\n    join = EmptyOperator(task_id=\"join\", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)\n\n    for option in options:\n        t = EmptyOperator(task_id=option)\n\n        empty_follow = EmptyOperator(task_id=\"follow_\" + option)\n\n        # Label is optional here, but it can help identify more complex branches\n        random_choice_instance >> Label(option) >> t >> empty_follow >> join", "metadata": {"file_name": "dag_2_variant_2", "instruction_source": "claude-3.5", "variant_number": 2}}
{"instruction": "Develop an Airflow DAG that simulates a decision-making process where a single task randomly determines which subsequent tasks will be executed. Create a workflow that demonstrates how to implement probabilistic routing in data processing pipelines using Airflow's task branching decorator.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"Example DAG demonstrating the usage of the ``@task.branch`` TaskFlow API decorator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_python_operator_decorator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(task_id=\"run_this_first\")\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    @task.branch(task_id=\"branching\")\n    def random_choice(choices: list[str]) -> str:\n        return random.choice(choices)\n\n    random_choice_instance = random_choice(choices=options)\n\n    run_this_first >> random_choice_instance\n\n    join = EmptyOperator(task_id=\"join\", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)\n\n    for option in options:\n        t = EmptyOperator(task_id=option)\n\n        empty_follow = EmptyOperator(task_id=\"follow_\" + option)\n\n        # Label is optional here, but it can help identify more complex branches\n        random_choice_instance >> Label(option) >> t >> empty_follow >> join", "metadata": {"file_name": "dag_2_variant_3", "instruction_source": "claude-3.5", "variant_number": 3}}
{"instruction": "Design a workflow that demonstrates conditional task execution based on the day of the week. Create a DAG that branches tasks differently for weekdays and weekends, showing how Airflow can dynamically route workflow paths.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"\nExample DAG demonstrating the usage of BranchDayOfWeekOperator.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.weekday import BranchDayOfWeekOperator\nfrom airflow.utils.weekday import WeekDay\n\nwith DAG(\n    dag_id=\"example_weekday_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    tags=[\"example\"],\n    schedule=\"@daily\",\n) as dag:\n    # [START howto_operator_day_of_week_branch]\n    empty_task_1 = EmptyOperator(task_id=\"branch_true\")\n    empty_task_2 = EmptyOperator(task_id=\"branch_false\")\n    empty_task_3 = EmptyOperator(task_id=\"branch_weekend\")\n    empty_task_4 = EmptyOperator(task_id=\"branch_mid_week\")\n\n    branch = BranchDayOfWeekOperator(\n        task_id=\"make_choice\",\n        follow_task_ids_if_true=\"branch_true\",\n        follow_task_ids_if_false=\"branch_false\",\n        week_day=\"Monday\",\n    )\n    branch_weekend = BranchDayOfWeekOperator(\n        task_id=\"make_weekend_choice\",\n        follow_task_ids_if_true=\"branch_weekend\",\n        follow_task_ids_if_false=\"branch_mid_week\",\n        week_day={WeekDay.SATURDAY, WeekDay.SUNDAY},\n    )\n\n    # Run empty_task_1 if branch executes on Monday, empty_task_2 otherwise\n    branch >> [empty_task_1, empty_task_2]\n    # Run empty_task_3 if it's a weekend, empty_task_4 otherwise\n    empty_task_2 >> branch_weekend >> [empty_task_3, empty_task_4]\n    # [END howto_operator_day_of_week_branch]", "metadata": {"file_name": "dag_3_variant_1", "instruction_source": "claude-3.5", "variant_number": 1}}
{"instruction": "Build an Airflow pipeline that showcases branching logic using BranchDayOfWeekOperator to demonstrate conditional task selection. Implement a workflow that executes different tasks based on whether the current day matches specific day criteria.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"\nExample DAG demonstrating the usage of BranchDayOfWeekOperator.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.weekday import BranchDayOfWeekOperator\nfrom airflow.utils.weekday import WeekDay\n\nwith DAG(\n    dag_id=\"example_weekday_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    tags=[\"example\"],\n    schedule=\"@daily\",\n) as dag:\n    # [START howto_operator_day_of_week_branch]\n    empty_task_1 = EmptyOperator(task_id=\"branch_true\")\n    empty_task_2 = EmptyOperator(task_id=\"branch_false\")\n    empty_task_3 = EmptyOperator(task_id=\"branch_weekend\")\n    empty_task_4 = EmptyOperator(task_id=\"branch_mid_week\")\n\n    branch = BranchDayOfWeekOperator(\n        task_id=\"make_choice\",\n        follow_task_ids_if_true=\"branch_true\",\n        follow_task_ids_if_false=\"branch_false\",\n        week_day=\"Monday\",\n    )\n    branch_weekend = BranchDayOfWeekOperator(\n        task_id=\"make_weekend_choice\",\n        follow_task_ids_if_true=\"branch_weekend\",\n        follow_task_ids_if_false=\"branch_mid_week\",\n        week_day={WeekDay.SATURDAY, WeekDay.SUNDAY},\n    )\n\n    # Run empty_task_1 if branch executes on Monday, empty_task_2 otherwise\n    branch >> [empty_task_1, empty_task_2]\n    # Run empty_task_3 if it's a weekend, empty_task_4 otherwise\n    empty_task_2 >> branch_weekend >> [empty_task_3, empty_task_4]\n    # [END howto_operator_day_of_week_branch]", "metadata": {"file_name": "dag_3_variant_2", "instruction_source": "claude-3.5", "variant_number": 2}}
{"instruction": "Develop an Airflow DAG that illustrates dynamic task routing using day-of-week conditions for data processing workflows. Create a scenario where tasks are selectively executed based on whether the current day meets predefined scheduling requirements.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"\nExample DAG demonstrating the usage of BranchDayOfWeekOperator.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.weekday import BranchDayOfWeekOperator\nfrom airflow.utils.weekday import WeekDay\n\nwith DAG(\n    dag_id=\"example_weekday_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    tags=[\"example\"],\n    schedule=\"@daily\",\n) as dag:\n    # [START howto_operator_day_of_week_branch]\n    empty_task_1 = EmptyOperator(task_id=\"branch_true\")\n    empty_task_2 = EmptyOperator(task_id=\"branch_false\")\n    empty_task_3 = EmptyOperator(task_id=\"branch_weekend\")\n    empty_task_4 = EmptyOperator(task_id=\"branch_mid_week\")\n\n    branch = BranchDayOfWeekOperator(\n        task_id=\"make_choice\",\n        follow_task_ids_if_true=\"branch_true\",\n        follow_task_ids_if_false=\"branch_false\",\n        week_day=\"Monday\",\n    )\n    branch_weekend = BranchDayOfWeekOperator(\n        task_id=\"make_weekend_choice\",\n        follow_task_ids_if_true=\"branch_weekend\",\n        follow_task_ids_if_false=\"branch_mid_week\",\n        week_day={WeekDay.SATURDAY, WeekDay.SUNDAY},\n    )\n\n    # Run empty_task_1 if branch executes on Monday, empty_task_2 otherwise\n    branch >> [empty_task_1, empty_task_2]\n    # Run empty_task_3 if it's a weekend, empty_task_4 otherwise\n    empty_task_2 >> branch_weekend >> [empty_task_3, empty_task_4]\n    # [END howto_operator_day_of_week_branch]", "metadata": {"file_name": "dag_3_variant_3", "instruction_source": "claude-3.5", "variant_number": 3}}
{"instruction": "Design a data quality monitoring workflow that tracks data integrity during an ingestion process. Create a DAG that handles both successful data processing and error scenarios with clear branching and reporting.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"\nExample DAG demonstrating the usage of labels with different branches.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\nwith DAG(\n    \"example_branch_labels\",\n    schedule=\"@daily\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n) as dag:\n    ingest = EmptyOperator(task_id=\"ingest\")\n    analyse = EmptyOperator(task_id=\"analyze\")\n    check = EmptyOperator(task_id=\"check_integrity\")\n    describe = EmptyOperator(task_id=\"describe_integrity\")\n    error = EmptyOperator(task_id=\"email_error\")\n    save = EmptyOperator(task_id=\"save\")\n    report = EmptyOperator(task_id=\"report\")\n\n    ingest >> analyse >> check\n    check >> Label(\"No errors\") >> save >> report\n    check >> Label(\"Errors found\") >> describe >> error >> report", "metadata": {"file_name": "dag_4_variant_1", "instruction_source": "claude-3.5", "variant_number": 1}}
{"instruction": "Build an Airflow pipeline that demonstrates conditional task execution based on data integrity checks. Implement a workflow that can automatically route tasks differently depending on whether data passes or fails validation.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"\nExample DAG demonstrating the usage of labels with different branches.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\nwith DAG(\n    \"example_branch_labels\",\n    schedule=\"@daily\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n) as dag:\n    ingest = EmptyOperator(task_id=\"ingest\")\n    analyse = EmptyOperator(task_id=\"analyze\")\n    check = EmptyOperator(task_id=\"check_integrity\")\n    describe = EmptyOperator(task_id=\"describe_integrity\")\n    error = EmptyOperator(task_id=\"email_error\")\n    save = EmptyOperator(task_id=\"save\")\n    report = EmptyOperator(task_id=\"report\")\n\n    ingest >> analyse >> check\n    check >> Label(\"No errors\") >> save >> report\n    check >> Label(\"Errors found\") >> describe >> error >> report", "metadata": {"file_name": "dag_4_variant_2", "instruction_source": "claude-3.5", "variant_number": 2}}
{"instruction": "Develop a data processing pipeline that includes stages for data ingestion, analysis, integrity verification, and error handling. Create a workflow that can gracefully manage data quality issues and generate appropriate reports or alerts.", "input": {"airflow_version": "2.7.2"}, "output": "\"\"\"\nExample DAG demonstrating the usage of labels with different branches.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\nwith DAG(\n    \"example_branch_labels\",\n    schedule=\"@daily\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n) as dag:\n    ingest = EmptyOperator(task_id=\"ingest\")\n    analyse = EmptyOperator(task_id=\"analyze\")\n    check = EmptyOperator(task_id=\"check_integrity\")\n    describe = EmptyOperator(task_id=\"describe_integrity\")\n    error = EmptyOperator(task_id=\"email_error\")\n    save = EmptyOperator(task_id=\"save\")\n    report = EmptyOperator(task_id=\"report\")\n\n    ingest >> analyse >> check\n    check >> Label(\"No errors\") >> save >> report\n    check >> Label(\"Errors found\") >> describe >> error >> report", "metadata": {"file_name": "dag_4_variant_3", "instruction_source": "claude-3.5", "variant_number": 3}}
