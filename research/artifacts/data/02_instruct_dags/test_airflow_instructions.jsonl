{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Design a dynamic workflow that randomly selects one of four predefined processing branches during each daily execution. Create a DAG that demonstrates flexible task routing with a guaranteed convergence point.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the BranchPythonOperator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.python import BranchPythonOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(\n        task_id=\"run_this_first\",\n    )\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    branching = BranchPythonOperator(\n        task_id=\"branching\",\n        python_callable=lambda: random.choice(options),\n    )\n    run_this_first >> branching\n\n    join = EmptyOperator(\n        task_id=\"join\",\n        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,\n    )\n\n    for option in options:\n        t = EmptyOperator(\n            task_id=option,\n        )\n\n        empty_follow = EmptyOperator(\n            task_id=\"follow_\" + option,\n        )\n\n        # Label is optional here, but it can help identify more complex branches\n        branching >> Label(option) >> t >> empty_follow >> join"}], "metadata": {"file_name": "generated_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Build an Airflow pipeline that showcases conditional task execution using a branching strategy, where a random selection determines which workflow path will be followed. Implement a join mechanism that ensures the workflow completes successfully regardless of the chosen branch.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the BranchPythonOperator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.python import BranchPythonOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(\n        task_id=\"run_this_first\",\n    )\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    branching = BranchPythonOperator(\n        task_id=\"branching\",\n        python_callable=lambda: random.choice(options),\n    )\n    run_this_first >> branching\n\n    join = EmptyOperator(\n        task_id=\"join\",\n        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,\n    )\n\n    for option in options:\n        t = EmptyOperator(\n            task_id=option,\n        )\n\n        empty_follow = EmptyOperator(\n            task_id=\"follow_\" + option,\n        )\n\n        # Label is optional here, but it can help identify more complex branches\n        branching >> Label(option) >> t >> empty_follow >> join"}], "metadata": {"file_name": "generated_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Develop an example data processing workflow that simulates different processing scenarios through random branch selection. Construct a DAG that demonstrates how to handle multiple potential execution paths with a unified completion strategy.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the BranchPythonOperator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.python import BranchPythonOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(\n        task_id=\"run_this_first\",\n    )\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    branching = BranchPythonOperator(\n        task_id=\"branching\",\n        python_callable=lambda: random.choice(options),\n    )\n    run_this_first >> branching\n\n    join = EmptyOperator(\n        task_id=\"join\",\n        trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS,\n    )\n\n    for option in options:\n        t = EmptyOperator(\n            task_id=option,\n        )\n\n        empty_follow = EmptyOperator(\n            task_id=\"follow_\" + option,\n        )\n\n        # Label is optional here, but it can help identify more complex branches\n        branching >> Label(option) >> t >> empty_follow >> join"}], "metadata": {"file_name": "generated_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Design a demonstration DAG that showcases multiple Bash command executions with different task dependencies and behaviors. Create a workflow that includes sequential tasks, looped tasks, and an example of a task that intentionally skips or fails.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the BashOperator.\"\"\"\nfrom __future__ import annotations\n\nimport datetime\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.empty import EmptyOperator\n\nwith DAG(\n    dag_id=\"example_bash_operator\",\n    schedule=\"0 0 * * *\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    dagrun_timeout=datetime.timedelta(minutes=60),\n    tags=[\"example\", \"example2\"],\n    params={\"example_key\": \"example_value\"},\n) as dag:\n    run_this_last = EmptyOperator(\n        task_id=\"run_this_last\",\n    )\n\n    # [START howto_operator_bash]\n    run_this = BashOperator(\n        task_id=\"run_after_loop\",\n        bash_command=\"echo 1\",\n    )\n    # [END howto_operator_bash]\n\n    run_this >> run_this_last\n\n    for i in range(3):\n        task = BashOperator(\n            task_id=f\"runme_{i}\",\n            bash_command='echo \"{{ task_instance_key_str }}\" && sleep 1',\n        )\n        task >> run_this\n\n    # [START howto_operator_bash_template]\n    also_run_this = BashOperator(\n        task_id=\"also_run_this\",\n        bash_command='echo \"ti_key={{ task_instance_key_str }}\"',\n    )\n    # [END howto_operator_bash_template]\n    also_run_this >> run_this_last\n\n# [START howto_operator_bash_skip]\nthis_will_skip = BashOperator(\n    task_id=\"this_will_skip\",\n    bash_command='echo \"hello world\"; exit 99;',\n    dag=dag,\n)\n# [END howto_operator_bash_skip]\nthis_will_skip >> run_this_last\n\nif __name__ == \"__main__\":\n    dag.test()"}], "metadata": {"file_name": "generated_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Build an Airflow pipeline that illustrates core orchestration patterns like task chaining, parallel execution, and conditional task handling using Bash commands. Develop a DAG that explores different operator behaviors and dependency management techniques.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the BashOperator.\"\"\"\nfrom __future__ import annotations\n\nimport datetime\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.empty import EmptyOperator\n\nwith DAG(\n    dag_id=\"example_bash_operator\",\n    schedule=\"0 0 * * *\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    dagrun_timeout=datetime.timedelta(minutes=60),\n    tags=[\"example\", \"example2\"],\n    params={\"example_key\": \"example_value\"},\n) as dag:\n    run_this_last = EmptyOperator(\n        task_id=\"run_this_last\",\n    )\n\n    # [START howto_operator_bash]\n    run_this = BashOperator(\n        task_id=\"run_after_loop\",\n        bash_command=\"echo 1\",\n    )\n    # [END howto_operator_bash]\n\n    run_this >> run_this_last\n\n    for i in range(3):\n        task = BashOperator(\n            task_id=f\"runme_{i}\",\n            bash_command='echo \"{{ task_instance_key_str }}\" && sleep 1',\n        )\n        task >> run_this\n\n    # [START howto_operator_bash_template]\n    also_run_this = BashOperator(\n        task_id=\"also_run_this\",\n        bash_command='echo \"ti_key={{ task_instance_key_str }}\"',\n    )\n    # [END howto_operator_bash_template]\n    also_run_this >> run_this_last\n\n# [START howto_operator_bash_skip]\nthis_will_skip = BashOperator(\n    task_id=\"this_will_skip\",\n    bash_command='echo \"hello world\"; exit 99;',\n    dag=dag,\n)\n# [END howto_operator_bash_skip]\nthis_will_skip >> run_this_last\n\nif __name__ == \"__main__\":\n    dag.test()"}], "metadata": {"file_name": "generated_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Construct a sample data processing workflow that demonstrates how Bash commands can be integrated into an Airflow DAG for executing simple system-level operations. Create a pipeline that shows task sequencing, templating, and basic command execution strategies.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the BashOperator.\"\"\"\nfrom __future__ import annotations\n\nimport datetime\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.empty import EmptyOperator\n\nwith DAG(\n    dag_id=\"example_bash_operator\",\n    schedule=\"0 0 * * *\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    dagrun_timeout=datetime.timedelta(minutes=60),\n    tags=[\"example\", \"example2\"],\n    params={\"example_key\": \"example_value\"},\n) as dag:\n    run_this_last = EmptyOperator(\n        task_id=\"run_this_last\",\n    )\n\n    # [START howto_operator_bash]\n    run_this = BashOperator(\n        task_id=\"run_after_loop\",\n        bash_command=\"echo 1\",\n    )\n    # [END howto_operator_bash]\n\n    run_this >> run_this_last\n\n    for i in range(3):\n        task = BashOperator(\n            task_id=f\"runme_{i}\",\n            bash_command='echo \"{{ task_instance_key_str }}\" && sleep 1',\n        )\n        task >> run_this\n\n    # [START howto_operator_bash_template]\n    also_run_this = BashOperator(\n        task_id=\"also_run_this\",\n        bash_command='echo \"ti_key={{ task_instance_key_str }}\"',\n    )\n    # [END howto_operator_bash_template]\n    also_run_this >> run_this_last\n\n# [START howto_operator_bash_skip]\nthis_will_skip = BashOperator(\n    task_id=\"this_will_skip\",\n    bash_command='echo \"hello world\"; exit 99;',\n    dag=dag,\n)\n# [END howto_operator_bash_skip]\nthis_will_skip >> run_this_last\n\nif __name__ == \"__main__\":\n    dag.test()"}], "metadata": {"file_name": "generated_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Design a dynamic task routing system that randomly selects one of four predefined workflow branches during each daily execution. Create a workflow that demonstrates flexible task branching with random selection and guaranteed convergence.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the ``@task.branch`` TaskFlow API decorator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_python_operator_decorator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(task_id=\"run_this_first\")\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    @task.branch(task_id=\"branching\")\n    def random_choice(choices: list[str]) -> str:\n        return random.choice(choices)\n\n    random_choice_instance = random_choice(choices=options)\n\n    run_this_first >> random_choice_instance\n\n    join = EmptyOperator(task_id=\"join\", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)\n\n    for option in options:\n        t = EmptyOperator(task_id=option)\n\n        empty_follow = EmptyOperator(task_id=\"follow_\" + option)\n\n        # Label is optional here, but it can help identify more complex branches\n        random_choice_instance >> Label(option) >> t >> empty_follow >> join"}], "metadata": {"file_name": "generated_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Build an Airflow DAG that showcases conditional task execution using Python's random selection mechanism and task flow decorators. Implement a branching workflow that demonstrates how tasks can be dynamically selected and executed based on runtime decisions.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the ``@task.branch`` TaskFlow API decorator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_python_operator_decorator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(task_id=\"run_this_first\")\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    @task.branch(task_id=\"branching\")\n    def random_choice(choices: list[str]) -> str:\n        return random.choice(choices)\n\n    random_choice_instance = random_choice(choices=options)\n\n    run_this_first >> random_choice_instance\n\n    join = EmptyOperator(task_id=\"join\", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)\n\n    for option in options:\n        t = EmptyOperator(task_id=option)\n\n        empty_follow = EmptyOperator(task_id=\"follow_\" + option)\n\n        # Label is optional here, but it can help identify more complex branches\n        random_choice_instance >> Label(option) >> t >> empty_follow >> join"}], "metadata": {"file_name": "generated_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Develop an Airflow pipeline that simulates a multi-path data processing workflow with random branch selection and guaranteed task completion. Create a DAG that illustrates how complex workflows can be constructed with dynamic routing and minimal dependency constraints.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"Example DAG demonstrating the usage of the ``@task.branch`` TaskFlow API decorator.\"\"\"\nfrom __future__ import annotations\n\nimport random\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\nfrom airflow.utils.trigger_rule import TriggerRule\n\nwith DAG(\n    dag_id=\"example_branch_python_operator_decorator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    schedule=\"@daily\",\n    tags=[\"example\", \"example2\"],\n) as dag:\n    run_this_first = EmptyOperator(task_id=\"run_this_first\")\n\n    options = [\"branch_a\", \"branch_b\", \"branch_c\", \"branch_d\"]\n\n    @task.branch(task_id=\"branching\")\n    def random_choice(choices: list[str]) -> str:\n        return random.choice(choices)\n\n    random_choice_instance = random_choice(choices=options)\n\n    run_this_first >> random_choice_instance\n\n    join = EmptyOperator(task_id=\"join\", trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)\n\n    for option in options:\n        t = EmptyOperator(task_id=option)\n\n        empty_follow = EmptyOperator(task_id=\"follow_\" + option)\n\n        # Label is optional here, but it can help identify more complex branches\n        random_choice_instance >> Label(option) >> t >> empty_follow >> join"}], "metadata": {"file_name": "generated_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Create a workflow that demonstrates task branching based on the day of the week, showing how different tasks can be executed conditionally depending on whether it's a specific day or a weekend. Design a DAG that splits processing paths for Monday and non-Monday days, and then further splits non-Monday days into weekend and weekday branches.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"\nExample DAG demonstrating the usage of BranchDayOfWeekOperator.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.weekday import BranchDayOfWeekOperator\nfrom airflow.utils.weekday import WeekDay\n\nwith DAG(\n    dag_id=\"example_weekday_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    tags=[\"example\"],\n    schedule=\"@daily\",\n) as dag:\n    # [START howto_operator_day_of_week_branch]\n    empty_task_1 = EmptyOperator(task_id=\"branch_true\")\n    empty_task_2 = EmptyOperator(task_id=\"branch_false\")\n    empty_task_3 = EmptyOperator(task_id=\"branch_weekend\")\n    empty_task_4 = EmptyOperator(task_id=\"branch_mid_week\")\n\n    branch = BranchDayOfWeekOperator(\n        task_id=\"make_choice\",\n        follow_task_ids_if_true=\"branch_true\",\n        follow_task_ids_if_false=\"branch_false\",\n        week_day=\"Monday\",\n    )\n    branch_weekend = BranchDayOfWeekOperator(\n        task_id=\"make_weekend_choice\",\n        follow_task_ids_if_true=\"branch_weekend\",\n        follow_task_ids_if_false=\"branch_mid_week\",\n        week_day={WeekDay.SATURDAY, WeekDay.SUNDAY},\n    )\n\n    # Run empty_task_1 if branch executes on Monday, empty_task_2 otherwise\n    branch >> [empty_task_1, empty_task_2]\n    # Run empty_task_3 if it's a weekend, empty_task_4 otherwise\n    empty_task_2 >> branch_weekend >> [empty_task_3, empty_task_4]\n    # [END howto_operator_day_of_week_branch]"}], "metadata": {"file_name": "generated_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Build an Airflow DAG that showcases dynamic task routing using BranchDayOfWeekOperator, illustrating how data pipelines can intelligently select execution paths based on calendar conditions. Implement a workflow that changes task execution strategy depending on whether the current day matches predefined day-of-week criteria.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"\nExample DAG demonstrating the usage of BranchDayOfWeekOperator.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.weekday import BranchDayOfWeekOperator\nfrom airflow.utils.weekday import WeekDay\n\nwith DAG(\n    dag_id=\"example_weekday_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    tags=[\"example\"],\n    schedule=\"@daily\",\n) as dag:\n    # [START howto_operator_day_of_week_branch]\n    empty_task_1 = EmptyOperator(task_id=\"branch_true\")\n    empty_task_2 = EmptyOperator(task_id=\"branch_false\")\n    empty_task_3 = EmptyOperator(task_id=\"branch_weekend\")\n    empty_task_4 = EmptyOperator(task_id=\"branch_mid_week\")\n\n    branch = BranchDayOfWeekOperator(\n        task_id=\"make_choice\",\n        follow_task_ids_if_true=\"branch_true\",\n        follow_task_ids_if_false=\"branch_false\",\n        week_day=\"Monday\",\n    )\n    branch_weekend = BranchDayOfWeekOperator(\n        task_id=\"make_weekend_choice\",\n        follow_task_ids_if_true=\"branch_weekend\",\n        follow_task_ids_if_false=\"branch_mid_week\",\n        week_day={WeekDay.SATURDAY, WeekDay.SUNDAY},\n    )\n\n    # Run empty_task_1 if branch executes on Monday, empty_task_2 otherwise\n    branch >> [empty_task_1, empty_task_2]\n    # Run empty_task_3 if it's a weekend, empty_task_4 otherwise\n    empty_task_2 >> branch_weekend >> [empty_task_3, empty_task_4]\n    # [END howto_operator_day_of_week_branch]"}], "metadata": {"file_name": "generated_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Develop an Airflow pipeline that demonstrates conditional data processing workflows triggered by calendar-based logic, showing how different data handling tasks can be selected based on the current day of the week. Create a DAG that dynamically chooses processing paths for Monday, weekend, and weekday scenarios to simulate real-world scheduling requirements.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"\nExample DAG demonstrating the usage of BranchDayOfWeekOperator.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.operators.weekday import BranchDayOfWeekOperator\nfrom airflow.utils.weekday import WeekDay\n\nwith DAG(\n    dag_id=\"example_weekday_branch_operator\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n    tags=[\"example\"],\n    schedule=\"@daily\",\n) as dag:\n    # [START howto_operator_day_of_week_branch]\n    empty_task_1 = EmptyOperator(task_id=\"branch_true\")\n    empty_task_2 = EmptyOperator(task_id=\"branch_false\")\n    empty_task_3 = EmptyOperator(task_id=\"branch_weekend\")\n    empty_task_4 = EmptyOperator(task_id=\"branch_mid_week\")\n\n    branch = BranchDayOfWeekOperator(\n        task_id=\"make_choice\",\n        follow_task_ids_if_true=\"branch_true\",\n        follow_task_ids_if_false=\"branch_false\",\n        week_day=\"Monday\",\n    )\n    branch_weekend = BranchDayOfWeekOperator(\n        task_id=\"make_weekend_choice\",\n        follow_task_ids_if_true=\"branch_weekend\",\n        follow_task_ids_if_false=\"branch_mid_week\",\n        week_day={WeekDay.SATURDAY, WeekDay.SUNDAY},\n    )\n\n    # Run empty_task_1 if branch executes on Monday, empty_task_2 otherwise\n    branch >> [empty_task_1, empty_task_2]\n    # Run empty_task_3 if it's a weekend, empty_task_4 otherwise\n    empty_task_2 >> branch_weekend >> [empty_task_3, empty_task_4]\n    # [END howto_operator_day_of_week_branch]"}], "metadata": {"file_name": "generated_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Design a data quality workflow that checks the integrity of ingested data and handles both successful and error scenarios. Create a process that automatically routes data through validation, saving, and reporting steps based on the integrity check results.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"\nExample DAG demonstrating the usage of labels with different branches.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\nwith DAG(\n    \"example_branch_labels\",\n    schedule=\"@daily\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n) as dag:\n    ingest = EmptyOperator(task_id=\"ingest\")\n    analyse = EmptyOperator(task_id=\"analyze\")\n    check = EmptyOperator(task_id=\"check_integrity\")\n    describe = EmptyOperator(task_id=\"describe_integrity\")\n    error = EmptyOperator(task_id=\"email_error\")\n    save = EmptyOperator(task_id=\"save\")\n    report = EmptyOperator(task_id=\"report\")\n\n    ingest >> analyse >> check\n    check >> Label(\"No errors\") >> save >> report\n    check >> Label(\"Errors found\") >> describe >> error >> report"}], "metadata": {"file_name": "generated_variant_1", "instruction_source": "claude-3.5", "variant_number": 1, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Build an Airflow DAG that demonstrates a robust data pipeline with branching logic for error handling and reporting. Implement a workflow that sequentially processes data through ingestion, analysis, integrity checking, and conditional downstream tasks.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"\nExample DAG demonstrating the usage of labels with different branches.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\nwith DAG(\n    \"example_branch_labels\",\n    schedule=\"@daily\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n) as dag:\n    ingest = EmptyOperator(task_id=\"ingest\")\n    analyse = EmptyOperator(task_id=\"analyze\")\n    check = EmptyOperator(task_id=\"check_integrity\")\n    describe = EmptyOperator(task_id=\"describe_integrity\")\n    error = EmptyOperator(task_id=\"email_error\")\n    save = EmptyOperator(task_id=\"save\")\n    report = EmptyOperator(task_id=\"report\")\n\n    ingest >> analyse >> check\n    check >> Label(\"No errors\") >> save >> report\n    check >> Label(\"Errors found\") >> describe >> error >> report"}], "metadata": {"file_name": "generated_variant_2", "instruction_source": "claude-3.5", "variant_number": 2, "airflow_version": "2.7.2"}}
{"messages": [{"role": "system", "content": "You are an expert Apache Airflow developer. Generate complete, valid Airflow DAGs based on given requirements."}, {"role": "user", "content": "Develop an automated data processing pipeline that validates data quality and manages different execution paths based on integrity check results. Create a workflow that supports successful data processing and provides error tracking and notification mechanisms.\n\nAirflow Version: 2.7.2"}, {"role": "assistant", "content": "\"\"\"\nExample DAG demonstrating the usage of labels with different branches.\n\"\"\"\nfrom __future__ import annotations\n\nimport pendulum\n\nfrom airflow import DAG\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\nwith DAG(\n    \"example_branch_labels\",\n    schedule=\"@daily\",\n    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n    catchup=False,\n) as dag:\n    ingest = EmptyOperator(task_id=\"ingest\")\n    analyse = EmptyOperator(task_id=\"analyze\")\n    check = EmptyOperator(task_id=\"check_integrity\")\n    describe = EmptyOperator(task_id=\"describe_integrity\")\n    error = EmptyOperator(task_id=\"email_error\")\n    save = EmptyOperator(task_id=\"save\")\n    report = EmptyOperator(task_id=\"report\")\n\n    ingest >> analyse >> check\n    check >> Label(\"No errors\") >> save >> report\n    check >> Label(\"Errors found\") >> describe >> error >> report"}], "metadata": {"file_name": "generated_variant_3", "instruction_source": "claude-3.5", "variant_number": 3, "airflow_version": "2.7.2"}}
